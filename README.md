# **Th√¥ng Tin D·ª± √Ån**

> **T√™n D·ª± √Ån**: Nh·∫≠n di·ªán bi·ªÉn b√°o giao th√¥ng
>
> **T√™n nh√≥m:** H·ªôi ng∆∞·ªùi cao tu·ªïi

**Ng√†y th·ª±c hi·ªán:** 14/05/2024

>

**Repostories Github:** https://github.com/SmrfHdl/Machine-Learning-Project---UET-.git

# **C√°c th√†nh vi√™n c·ªßa nh√≥m:**

| H·ªç t√™n                       | MSSV     |
| ---------------------------- | -------- |
| Nguy·ªÖn Vi·∫øt V≈© (Tr∆∞·ªüng nh√≥m) | 22022632 |
| Ph·∫°m VƒÉn Tr∆∞·ªùng              | 22022564 |
| Tr·∫ßn An Th·∫Øng                | 22022525 |

</aside>

# 1. T·ªïng quan v·ªÅ d·ª± √°n

## 1.1. T·ªïng quan

Ng√†y nay, c∆° s·ªü h·∫° t·∫ßng giao th√¥ng ng√†y c√†ng ph√°t tri·ªÉn, vi·ªác ph√°t hi·ªán bi·ªÉn b√°o ƒë·ªÉ cung c·∫•p th√¥ng tin ƒë·∫øn ng∆∞·ªùi tham gia giao th√¥ng l√† m·ªôt ƒëi·ªÅu r·∫•t quan tr·ªçng. T·∫≠n d·ª•ng nh·ªØng ki·∫øn th·ª©c ƒë√£ ƒë∆∞·ª£c h·ªçc ·ªü m√¥n Machine Learning, k·∫øt h·ª£p v·ªõi nh·ªØng ƒëi·ªÅu g·∫ßn g≈©i v·ªõi ƒë·ªùi s·ªëng. Nh√≥m t√¥i ƒë√£ ch·ªçn ƒë·ªÅ t√†i ‚ÄúPh√°t hi·ªán c√°c lo·∫°i bi·ªÉn b√°o giao th√¥ng‚Äù l√†m ƒë·ªÅ t√†i nghi√™n c·ª©u. Gi√∫p m·ªçi ng∆∞·ªùi c√≥ th·ªÉ hi·ªÉu ƒë√¢u l√† bi·ªÉn b√°o giao th√¥ng v√† ch√∫ng c√≥ √Ω nghƒ©a th·∫ø n√†o.

## 1.2. M√¥ t·∫£ b√†i to√°n

1. Input: M·ªôt b·ª©c ·∫£nh c√≥ ch·ª©a bi·ªÉn b√°o
2. Output: T√™n bi·ªÉn b√°o

# 2. X√¢y d·ª±ng b·ªô d·ªØ li·ªáu

V·ªÅ d·ªØ li·ªáu, nh√≥m t√¥i s·∫Ω s·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu bi·ªÉn b√°o giao th√¥ng n·ªïi ti·∫øng ƒë√≥ l√† German Traffic Sign.

B·ªô d·ªØ li·ªáu German Traffic Sign (GTSRB) l√† m·ªôt b·ªô d·ªØ li·ªáu ch·ª©a h√¨nh ·∫£nh v·ªÅ c√°c bi·ªÉn b√°o giao th√¥ng ƒê·ª©c, ƒë∆∞·ª£c s·ª≠ d·ª•ng ph·ªï bi·∫øn trong lƒ©nh v·ª±c nh·∫≠n d·∫°ng bi·ªÉn b√°o giao th√¥ng v√† th·ªã gi√°c m√°y t√≠nh. B·ªô d·ªØ li·ªáu n√†y th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán v√† ƒë√°nh gi√° c√°c m√¥ h√¨nh h·ªçc m√°y v√† m·∫°ng n∆°-ron s√¢u trong vi·ªác nh·∫≠n d·∫°ng c√°c bi·ªÉn b√°o giao th√¥ng.

## 2.1. Th√¥ng tin v·ªÅ b·ªô d·ªØ li·ªáu

B·ªô d·ªØ li·ªáu n√†y g·ªìm kho·∫£ng g·∫ßn 40k ·∫£nh chia th√†nh 43 folder l√† 43 lo·∫°i bi·ªÉn b√°o kh√°c nhau. M·ªói folder s·∫Ω c√≥ 1 file CSV ch·ª©a th√¥ng tin c√°c ·∫£nh trong th∆∞ m·ª•c.

| Nh√£n | Bi·ªÉn t∆∞∆°ng ·ª©ng               | Nh√£n | Bi·ªÉn t∆∞∆°ng ·ª©ng            | Nh√£n | Bi·ªÉn t∆∞∆°ng ·ª©ng             | Nh√£n | Bi·ªÉn t∆∞∆°ng ·ª©ng                |
| ---- | ---------------------------- | ---- | ------------------------- | ---- | -------------------------- | ---- | ----------------------------- |
| 0    | Speed limit (20km/h)         | 12   | Priority road             | 24   | Road narrows on the right  | 36   | Go straight or right          |
| 1    | Speed limit (30km/h)         | 13   | Yield                     | 25   | Road work                  | 37   | Go straight or left           |
| 2    | Speed limit (50km/h)         | 14   | Stop                      | 26   | Traffic signals            | 38   | Keep right                    |
| 3    | Speed limit (60km/h)         | 15   | No vehicles               | 27   | Pedestrians                | 39   | Keep left                     |
| 4    | Speed limit (70km/h)         | 16   | Veh > 3.5 tons prohibited | 28   | Children crossing          | 40   | Roundabout mandatory          |
| 5    | Speed limit (80km/h)         | 17   | No Entry                  | 29   | Bicycles crossing          | 41   | End of no passing             |
| 6    | End of speed limit (80km/h)  | 18   | General caution           | 30   | Beware of ice/snow         | 42   | End no passing veh > 3.5 tons |
| 7    | Speed limit (100km/h)        | 19   | Dangerous curve left      | 31   | Wild animals crossing      |      |                               |
| 8    | Speed limit (120km/h)        | 20   | Dangerous curve right     | 32   | End speed + passing limits |      |                               |
| 9    | No passing                   | 21   | Double curve              | 33   | Turn right ahead           |      |                               |
| 10   | No passing veh over 3.5 tons | 22   | Bumpy road                | 34   | Turn left ahead            |      |                               |
| 11   | Right-of-way at intersection | 23   | Slippery road             | 35   | Ahead only                 |      |                               |

D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë th√¥ng tin chi ti·∫øt v·ªÅ b·ªô d·ªØ li·ªáu GTSRB:

- **S·ªë L∆∞·ª£ng L·ªõp**: 43 (m·ªói l·ªõp t∆∞∆°ng ·ª©ng v·ªõi m·ªôt lo·∫°i bi·ªÉn b√°o giao th√¥ng)
- **K√≠ch Th∆∞·ªõc H√¨nh ·∫¢nh**: ƒêa d·∫°ng, th∆∞·ªùng l√† 32x32 pixel ho·∫∑c 64x64 pixel
- **S·ªë L∆∞·ª£ng H√¨nh ·∫¢nh**: Kho·∫£ng 50,000 h√¨nh ·∫£nh ƒë∆∞·ª£c chia th√†nh t·∫≠p hu·∫•n luy·ªán, t·∫≠p x√°c th·ª±c v√† t·∫≠p ki·ªÉm th·ª≠
- **ƒê·ªãnh D·∫°ng H√¨nh ·∫¢nh**: PNG ho·∫∑c JPEG

## 2.2. ƒê·ªçc v√† x·ª≠ l√Ω d·ªØ li·ªáu

B·ªüi v√¨ t·∫≠p d·ªØ li·ªáu ·ªü d·∫°ng ·∫£nh, kh√¥ng th·ªÉ tr·ª±c ti·∫øp ƒë∆∞a v√†o model ƒë·ªÉ ti·∫øn h√†nh trainning, v√¨ v·∫≠y t√¥i c·∫ßn ph·∫£i tr√≠ch xu·∫•t nh·ªØng ƒë·∫∑c tr∆∞ng c·ªßa ·∫£nh. V√† k·ªπ thu·∫≠t ƒë∆∞·ª£c s·ª≠ d·ª•ng ·ªü ƒë√¢y l√† HOG (Histograms of Oriented Gradients)

### 2.2.1. HOG (Histograms of Oriented Gradients)

T√¥i s·∫Ω s·ª≠ d·ª•ng HOG((histogram of oriented gradients) ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng tr√™n nh·ªØng v√πng m√† c·ª≠a s·ªï tr∆∞·ª£t qua.

Histograms of Oriented Gradients (HOG) l√† m·ªôt k·ªπ thu·∫≠t tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ h√¨nh ·∫£nh, ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong c√°c b√†i to√°n th·ªã gi√°c m√°y t√≠nh nh∆∞ ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng v√† nh·∫≠n d·∫°ng m·∫´u. HOG ƒë∆∞·ª£c gi·ªõi thi·ªáu b·ªüi Navneet Dalal v√† Bill Triggs v√†o nƒÉm 2005 trong b√†i b√°o "Histograms of Oriented Gradients for Human Detection".

**Nguy√™n l√Ω ho·∫°t ƒë·ªông:**

HOG ho·∫°t ƒë·ªông d·ª±a tr√™n vi·ªác ƒë·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa c√°c gradient ƒë·ªãnh h∆∞·ªõng (h∆∞·ªõng c·ªßa s·ª± thay ƒë·ªïi c∆∞·ªùng ƒë·ªô m√†u s·∫Øc) trong c√°c v√πng c·ª•c b·ªô c·ªßa h√¨nh ·∫£nh. Qu√° tr√¨nh tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng HOG bao g·ªìm c√°c b∆∞·ªõc ch√≠nh sau:

- **T√≠nh to√°n gradient:** S·ª≠ d·ª•ng b·ªô l·ªçc Sobel ƒë·ªÉ t√≠nh to√°n h∆∞·ªõng v√† ƒë·ªô l·ªõn c·ªßa gradient t·∫°i m·ªói pixel trong ·∫£nh.
- **Ph√¢n lo·∫°i h∆∞·ªõng:** Chia h√¨nh ·∫£nh th√†nh c√°c √¥ (cell) nh·ªè, th∆∞·ªùng l√† 8x8 pixel, v√† t√≠nh histogram c·ªßa c√°c gradient trong m·ªói √¥, v·ªõi c√°c h∆∞·ªõng ƒë∆∞·ª£c chia th√†nh c√°c th√πng (bin) d·ª±a tr√™n ƒë·ªô l·ªõn c·ªßa ch√∫ng.
- **Chu·∫©n h√≥a kh·ªëi:** Gh√©p c√°c √¥ th√†nh c√°c kh·ªëi (block) l·ªõn h∆°n, th∆∞·ªùng l√† 2x2 √¥, v√† chu·∫©n h√≥a c√°c histogram ƒë·ªÉ gi·∫£m thi·ªÉu ·∫£nh h∆∞·ªüng c·ªßa √°nh s√°ng v√† ƒë·ªô t∆∞∆°ng ph·∫£n.
- **T·∫°o vector ƒë·∫∑c tr∆∞ng:** K·∫øt h·ª£p t·∫•t c·∫£ c√°c vector ƒë·∫∑c tr∆∞ng c·ªßa c√°c kh·ªëi trong to√†n b·ªô h√¨nh ·∫£nh th√†nh m·ªôt vector ƒë·∫∑c tr∆∞ng duy nh·∫•t.

**L√Ω do ch·ªçn HOG ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng:**

- HOG s·∫Ω tr√≠ch xu·∫•t nh·ªØng ƒë·∫∑c tr∆∞ng c·ªßa ·∫£nh, t·ª´ ƒë√≥ gi·∫£m chi·ªÅu d·ªØ li·ªáu, gi·∫£m th·ªùi th·ªùi gian t√≠nh to√°n v√† gi·∫£m ƒë·ªô ph·ª©c t·∫°p c·ªßa m√¥ h√¨nh.
- HOG t·∫≠p trung v√†o s·ª± thay ƒë·ªïi c∆∞·ªùng ƒë·ªô (gradient) h∆°n l√† gi√° tr·ªã tuy·ªát ƒë·ªëi c·ªßa c∆∞·ªùng ƒë·ªô √°nh s√°ng. Do ƒë√≥, ngay c·∫£ khi √°nh s√°ng y·∫øu, c√°c c·∫°nh v√† ƒë∆∞·ªùng vi·ªÅn trong ·∫£nh v·∫´n t·∫°o ra c√°c gradient m√† HOG c√≥ th·ªÉ s·ª≠ d·ª•ng ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng. T·ª´ ƒë√≥ gi·∫£m b·ªõt c√°c b∆∞·ªõc ƒë·ªÉ ti·ªÅn x·ª≠ l√Ω ƒë·ªëi v·ªõi nh·ªØng ·∫£nh qu√° s√°ng ho·∫∑c qu√° t·ªëi.

T√¥i s·∫Ω vi·∫øt h√†m tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng v·ªõi ƒë·∫ßu v√†o l√† ƒë∆∞·ªùng d·∫´n ·∫£nh:

```python
def compute_hog(image_path):
    try:
        image = Image.open(image_path)
        image = image.convert("L")
        image = image.resize((128, 128))

        hog, _ = feature.hog(np.array(image), orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2),
                             visualize=True, transform_sqrt=True, block_norm='L2-Hys')
        return hog
    except Exception as e:
        logging.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh {image_path}: {e}")
        return None
```

Resize ·∫£nh th√†nh k√≠ch th∆∞·ªõc 128x128 pixels nh·∫±m gi√∫p cho ƒë·∫∑c tr∆∞ng ·∫£nh thu ƒë∆∞·ª£c kh√¥ng qu√° √≠t, ƒë·ªìng th·ªùi c≈©ng kh√¥ng t·∫°o ra qu√° nhi·ªÅu tham s·ªë gi·∫£m th·ªùi gian t·∫£i d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh.

### 2.2.2. ƒê·ªçc d·ªØ li·ªáu v√† tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng

ƒê·ªÉ ƒë·ªçc v√† tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ d·ªØ li·ªáu t√¥i s·ª≠ d·ª•ng ƒëo·∫°n code:

```python
def load_data_from_csv(csv_file):
    data = []
    labels = []

    with open(csv_file, 'r') as file:
        lines = file.readlines()[1:]  # B·ªè qua d√≤ng ti√™u ƒë·ªÅ
        for line in lines:
            parts = line.strip().split(',')
            image_path = parts[-1]
            hog = compute_hog(image_path)
            if hog is not None:
                data.append(hog)
                labels.append(int(parts[-2]))
    return np.array(data), np.array(labels)

X_train, Y_train = load_data_from_csv("./data/Train.csv")
```

ƒê·∫∑c tr∆∞ng c·ªßa m·ªói ·∫£nh ƒë∆∞·ª£c tr√≠ch xu·∫•t ra t·ª´ t·∫≠p training s·∫Ω l√† m·ªôt ƒëi·ªÉm d·ªØ li·ªáu trong m·ªôt kh√¥ng gian ƒëa chi·ªÅu. ·ªû ƒë√¢y v·ªõi ·∫£nh ƒë∆∞·ª£c resize th√†nh 128\*128px th√¨ s·ªë chi·ªÅu c·ªßa kh√¥ng gian n√†y s·∫Ω l√†:

$$
(\frac{128}{8}_{(cells)}-1).(\frac{128}{8}_{(cells)}-1).(9_{(bins)}.4_{(blocks)})=8100
$$

```python
array([0.21429373, 0.23669159, 0.23669159, ..., 0.01807657, 0.00958505, 0. ]) # Arr 1 chi·ªÅu 8100 features nh∆∞ m·ªôt ƒëi·ªÉm trong kh√¥ng gian ƒëa chi·ªÅu
```

### **2.2.3. Th·ªëng k√™ v√† x·ª≠ l√Ω d·ªØ li·ªáu kh√¥ng c√¢n b·∫±ng**

S·ªë l∆∞·ª£ng nh√£n ch√™nh l·ªách l√† r·∫•t l·ªõn, ƒëi·ªÅu n√†y s·∫Ω l√†m ph√°t sinh m·ªôt s·ªë v·∫•n ƒë·ªÅ:

- **Hi·ªáu su·∫•t kh√¥ng ƒë·ªìng ƒë·ªÅu:** M√¥ h√¨nh s·∫Ω c√≥ xu h∆∞·ªõng d·ª± ƒëo√°n nh√£n c√≥ nhi·ªÅu d·ªØ li·ªáu h∆°n. ƒêi·ªÅu n√†y l√†m cho m√¥ h√¨nh k√©m hi·ªáu qu·∫£ trong vi·ªác d·ª± ƒëo√°n nh√£n c√≥ √≠t d·ªØ li·ªáu.
- **ƒê·ªô ch√≠nh x√°c b·ªã l·ªách:** C√°c ch·ªâ s·ªë ƒë√°nh gi√° nh∆∞ ƒë·ªô ch√≠nh x√°c (accuracy) s·∫Ω b·ªã l·ªách n·∫øu kh√¥ng c√≥ s·ª± c√¢n b·∫±ng gi·ªØa c√°c nh√£n. M√¥ h√¨nh c√≥ th·ªÉ ƒë·∫°t ƒë·ªô ch√≠nh x√°c cao ƒë∆°n gi·∫£n v√¨ n√≥ ƒëo√°n ƒë√∫ng nhi·ªÅu m·∫´u t·ª´ nh√£n c√≥ nhi·ªÅu d·ªØ li·ªáu.

V·∫•n ƒë·ªÅ d·ªØ li·ªáu kh√¥ng c√¢n b·∫±ng c√≥ th·ªÉ ƒë∆∞·ª£c gi·∫£i quy·∫øt v·ªõi c√°c m√¥ h√¨nh Ensemble nh∆∞ Random Forest, tuy nhi√™n ƒë·ªÉ c√≥ th·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh SVM th√¨ t√¥i s·∫Ω c·∫ßn ph·∫£i s·ª≠ d·ª•ng k·ªπ thu·∫≠t Resampling b·∫±ng SMOTE c·ªßa th∆∞ vi·ªán ‚Äòimblearn‚Äô. SMOTE (Synthetic Minority Over-sampling) v√† ADASYN (Adaptive synthetic sampling) l√† c√°c ph∆∞∆°ng ph√°p sinh m·∫´u nh·∫±m gia tƒÉng k√≠ch th∆∞·ªõc m·∫´u c·ªßa nh√≥m thi·ªÉu s·ªë trong tr∆∞·ªùng h·ª£p x·∫£y ra m·∫•t c√¢n b·∫±ng m·∫´u. ƒê·ªÉ gia tƒÉng k√≠ch th∆∞·ªõc m·∫´u, v·ªõi m·ªói m·ªôt m·∫´u thu·ªôc nh√≥m thi·ªÉu s·ªë ta s·∫Ω l·ª±a ch·ªçn ra ùëò m·∫´u l√°ng gi·ªÅng g·∫ßn nh·∫•t v·ªõi n√≥ v√† sau ƒë√≥ th·ª±c hi·ªán t·ªï h·ª£p tuy·∫øn t√≠nh ƒë·ªÉ t·∫°o ra m·∫´u gi·∫£ l·∫≠p:

```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, Y_train)
```

Sau khi t√≠nh to√°n gi√° tr·ªã trung b√¨nh l√† kho·∫£ng 1000 d·ªØ li·ªáu tr√™n m·ªói nh√£n, t√¥i ti·∫øn h√†nh t·∫°o th√™m d·ªØ li·ªáu ƒë·ªÉ c√°c nh√£n c√≥ s·ªë d·ªØ li·ªáu qu√° th·∫•p ƒë·∫°t t·ªõi 1000 d·ªØ li·ªáu.

K·∫øt qu·∫£ cho th·∫•y h√†m ƒë√£ ho·∫°t ƒë·ªông t·ªët v√† cho ra t·∫≠p d·ªØ li·ªáu kh√° c√¢n b·∫±ng.

### 2.2.4. Chia t·∫≠p d·ªØ li·ªáu

Ti·∫øp theo ƒë·ªÉ c√≥ th·ªÉ ƒë√°nh gi√° v√† t·ªëi ∆∞u h√≥a m√¥ h√¨nh t√¥i s·∫Ω ti·∫øn h√†nh chia t·∫≠p d·ªØ li·ªáu th√†nh 3 ph·∫ßn train - val - test v·ªõi t·ªâ l·ªá 70% - 10% - 15%

```python
from sklearn.model_selection import train_test_split

x_train, x_remaining, y_train, y_remaining = train_test_split(X_train_resampled, y_train_resampled, test_size=0.25, random_state=42)
x_test, x_val, y_test, y_val = train_test_split(x_remaining, y_remaining, test_size=0.4, random_state=42)
```

D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng, t√¥i s·∫Ω ti·∫øn t·ªõi b∆∞·ªõc training model!!!

# 3. Training v√† ƒë√°nh gi√° m√¥ h√¨nh

## 3.1. Ch·ªçn base model ƒë·ªÉ training

Nh·ªØng model ƒë∆∞·ª£c t√¥i s·ª≠ d·ª•ng trong b√†i to√°n n√†y s·∫Ω l√† Support Vector Machine(SVM), K-Nearest Neighbor(KNN) v√† Random Forest(RF)

### **3.1.1. Support Vector Machine (SVM)**:

- SVM l√† m·ªôt l·ª±a ch·ªçn ph·ªï bi·∫øn khi l√†m vi·ªác v·ªõi d·ªØ li·ªáu c√≥ s·ªë l∆∞·ª£ng l·ªõn c√°c ƒë·∫∑c tr∆∞ng, nh∆∞ trong tr∆∞·ªùng h·ª£p c·ªßa HOG.
- SVM ho·∫°t ƒë·ªông t·ªët khi d·ªØ li·ªáu l√† tuy·∫øn t√≠nh ho·∫∑c c√≥ th·ªÉ chuy·ªÉn ƒë·ªïi th√†nh tuy·∫øn t√≠nh th√¥ng qua c√°c h√†m kernel.
- SVM c√≥ th·ªÉ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh b·∫±ng c√°ch thay ƒë·ªïi si√™u tham s·ªë nh∆∞ C (tham s·ªë ƒë√≤i h·ªèi m·∫°nh m·∫Ω) v√† kernel ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c hi·ªáu su·∫•t t·ªët nh·∫•t.

### 3.1.2. Random Forest:

- Random Forest l√† m·ªôt ph∆∞∆°ng ph√°p h·ªçc m√°y ensemble d·ª±a tr√™n c√¢y quy·∫øt ƒë·ªãnh.
- ƒê·ªëi v·ªõi d·ªØ li·ªáu HOG, Random Forest c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√¢y d·ª±ng m·ªôt t·∫≠p h·ª£p c√°c c√¢y quy·∫øt ƒë·ªãnh ƒë·ªÉ ph√¢n lo·∫°i ·∫£nh.
- ƒê·∫∑c ƒëi·ªÉm c·ªßa Random Forest l√† kh√¥ng nh·∫°y c·∫£m v·ªõi overfitting v√† c√≥ kh·∫£ nƒÉng l√†m vi·ªác t·ªët v·ªõi d·ªØ li·ªáu c√≥ nhi·ªÖu.

### 3.1.3. **K-Nearest Neighbors (KNN)**:

- KNN l√† m·ªôt ph∆∞∆°ng ph√°p h·ªçc m√°y ƒë∆°n gi·∫£n nh∆∞ng m·∫°nh m·∫Ω trong vi·ªác ph√¢n lo·∫°i d·ªØ li·ªáu.
- KNN ho·∫°t ƒë·ªông b·∫±ng c√°ch x√°c ƒë·ªãnh nh√£n cho m·ªôt ƒëi·ªÉm d·ªØ li·ªáu m·ªõi b·∫±ng c√°ch so s√°nh n√≥ v·ªõi c√°c ƒëi·ªÉm d·ªØ li·ªáu trong t·∫≠p hu·∫•n luy·ªán g·∫ßn nh·∫•t (K ƒëi·ªÉm g·∫ßn nh·∫•t).
- HOG c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ l√† ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o cho m·ªói ƒëi·ªÉm d·ªØ li·ªáu.
- KNN kh√¥ng c·∫ßn hu·∫•n luy·ªán tr∆∞·ªõc v√† c√≥ th·ªÉ √°p d·ª•ng tr·ª±c ti·∫øp v√†o d·ªØ li·ªáu m·ªõi m√† kh√¥ng c·∫ßn ph·∫£i t√°i hu·∫•n luy·ªán to√†n b·ªô m√¥ h√¨nh.

‚Üí Tuy nhi√™n, KNN c√≥ th·ªÉ ƒë√≤i h·ªèi nhi·ªÅu t√†i nguy√™n t√≠nh to√°n khi s·ªë l∆∞·ª£ng ƒëi·ªÉm d·ªØ li·ªáu trong t·∫≠p hu·∫•n luy·ªán l·ªõn.

## 3.2. ƒê√°nh gi√° c√°c base model

### 3.2.1. **ƒê√°nh gi√° m√¥ h√¨nh SVM**

```python
ƒê√°nh gi√° m√¥ h√¨nh SVM tr√™n d·ªØ li·ªáu validation:
Accuracy: 0.9451306413301662
Classification Report:
              precision    recall  f1-score   support

           0       0.90      0.90      0.90        60
           1       0.93      0.91      0.92       720
           2       0.90      0.96      0.93       750
           3       0.89      0.85      0.87       450
           4       0.97      0.97      0.97       660
           5       0.84      0.88      0.86       630
           6       0.99      0.79      0.88       150
           7       0.91      0.93      0.92       450
           8       0.91      0.87      0.89       450
           9       0.99      0.97      0.98       480
          10       0.96      0.98      0.97       660
          11       0.95      0.94      0.95       420
          12       0.99      1.00      0.99       690
          13       1.00      1.00      1.00       720
          14       0.98      0.99      0.98       270
          15       0.95      1.00      0.97       210
          16       0.97      0.97      0.97       150
          17       1.00      1.00      1.00       360
          18       0.99      0.93      0.96       390
          19       0.92      1.00      0.96        60
          20       0.87      0.91      0.89        90
```

```python
          21       0.93      0.83      0.88        90
          22       0.93      0.80      0.86       120
          23       0.92      0.85      0.89       150
          24       0.95      0.99      0.97        90
          25       0.92      0.96      0.94       480
          26       0.92      0.82      0.87       180
          27       1.00      1.00      1.00        60
          28       0.94      0.96      0.95       150
          29       0.79      0.93      0.85        90
          30       0.80      0.77      0.78       150
          31       0.92      0.99      0.95       270
          32       1.00      0.92      0.96        60
          33       0.97      1.00      0.98       210
          34       0.97      0.99      0.98       120
          35       0.98      0.98      0.98       390
          36       0.98      0.98      0.98       120
          37       1.00      0.95      0.97        60
          38       0.99      0.99      0.99       690
          39       0.98      1.00      0.99        90
          40       0.96      0.98      0.97        90
          41       0.91      0.83      0.87        60
          42       0.99      0.88      0.93        90

    accuracy                           0.95     12630
   macro avg       0.94      0.93      0.94     12630
weighted avg       0.95      0.95      0.94     12630
```

Trong b√°o c√°o ph√¢n lo·∫°i c·ªßa m√¥ h√¨nh SVM, ch√∫ng ta th·∫•y r·∫±ng precision, recall v√† f1-score ƒë·ªÅu cao cho h·∫ßu h·∫øt c√°c l·ªõp. ƒêi·ªÅu n√†y cho th·∫•y m√¥ h√¨nh SVM c√≥ kh·∫£ nƒÉng ph√¢n lo·∫°i t·ªët tr√™n c·∫£ c√°c l·ªõp l·ªõn v√† nh·ªè. Precision v√† recall g·∫ßn nh∆∞ ƒë·ªÅu cao cho t·∫•t c·∫£ c√°c l·ªõp, ch·ªâ c√≥ m·ªôt s·ªë l·ªõp c√≥ m·ªôt v√†i ƒëi·ªÉm s·ªë th·∫•p h∆°n, nh∆∞ng v·∫´n ƒë·∫°t ƒë∆∞·ª£c hi·ªáu su·∫•t t·ªët (v√≠ d·ª•: l·ªõp 6, l·ªõp 21, l·ªõp 22).

S·ªü dƒ© m√¥ h√¨nh SVM ƒë·∫°t ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c xao nh∆∞ v·∫≠y l√† v√¨ m√¥ h√¨nh n√†y ƒë·∫∑c bi·ªát ho·∫°t ƒë·ªông t·ªët tr√™n c√°c t·∫≠p d·ªØ li·ªáu nhi·ªÅu chi·ªÅu nh∆∞ ƒë·∫∑c tr∆∞ng HOG.

### 3.2.2. **ƒê√°nh gi√° m√¥ h√¨nh Random Forest**

```python
ƒê√°nh gi√° m√¥ h√¨nh Random Forest tr√™n d·ªØ li·ªáu validation:
Accuracy: 0.9346793349168646
Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.97      0.98        60
           1       0.95      0.87      0.91       720
           2       0.86      0.97      0.91       750
           3       0.97      0.84      0.90       450
           4       0.95      0.95      0.95       660
           5       0.82      0.90      0.86       630
           6       0.93      0.75      0.83       150
           7       0.89      0.92      0.91       450
           8       0.87      0.80      0.83       450
           9       0.96      0.97      0.97       480
          10       0.93      0.97      0.95       660
          11       0.91      0.96      0.93       420
          12       0.98      1.00      0.99       690
          13       1.00      1.00      1.00       720
          14       1.00      0.96      0.98       270
          15       0.98      0.99      0.98       210
          16       0.99      0.97      0.98       150
          17       0.99      0.99      0.99       360
          18       0.97      0.88      0.93       390
          19       0.97      1.00      0.98        60
          20       0.90      0.91      0.91        90
```

```python
          21       0.98      0.63      0.77        90
          22       0.99      0.84      0.91       120
          23       0.93      0.95      0.94       150
          24       1.00      0.98      0.99        90
          25       0.90      0.96      0.93       480
          26       0.82      0.77      0.80       180
          27       0.98      0.90      0.94        60
          28       0.94      0.95      0.94       150
          29       0.95      0.90      0.93        90
          30       0.90      0.79      0.84       150
          31       0.90      0.98      0.94       270
          32       0.94      0.82      0.88        60
          33       0.96      1.00      0.98       210
          34       0.99      0.99      0.99       120
          35       0.96      0.98      0.97       390
          36       0.98      0.98      0.98       120
          37       0.98      0.90      0.94        60
          38       0.96      0.99      0.98       690
          39       0.99      1.00      0.99        90
          40       0.94      0.84      0.89        90
          41       0.85      0.87      0.86        60
          42       0.97      0.78      0.86        90

    accuracy                           0.93     12630
   macro avg       0.94      0.92      0.93     12630
weighted avg       0.94      0.93      0.93     12630
```

B·∫£ng ƒë√°nh gi√° cho th·∫•y m√¥ h√¨nh c√≥ hi·ªáu su·∫•t t·ªët tr√™n h·∫ßu h·∫øt c√°c l·ªõp, v·ªõi precision, recall v√† F1-score ƒë·ªÅu ·ªïn ƒë·ªãnh. Random Forest ho·∫°t ƒë·ªông t·ªët tr√™n d·ªØ li·ªáu HOG v√¨ kh·∫£ nƒÉng x·ª≠ l√Ω kh√¥ng gian ƒë·∫∑c tr∆∞ng l·ªõn, d·ªÖ d√†ng √°nh x·∫° c√°c m·∫´u d·ªØ li·ªáu v√† kh√¥ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi bi·∫øn ƒë·ªïi kh√¥ng quan tr·ªçng c·ªßa d·ªØ li·ªáu.

### 3.2.3. **ƒê√°nh gi√° m√¥ h√¨nh KNN**

```python
ƒê√°nh gi√° m√¥ h√¨nh KNN tr√™n d·ªØ li·ªáu validation:
Accuracy: 0.66270783847981
Classification Report:
              precision    recall  f1-score   support

           0       0.09      0.97      0.16        60
           1       0.87      0.41      0.55       720
           2       0.93      0.57      0.71       750
           3       0.67      0.46      0.54       450
           4       0.94      0.74      0.83       660
           5       0.53      0.67      0.59       630
           6       0.74      0.73      0.73       150
           7       0.84      0.68      0.75       450
           8       0.70      0.76      0.73       450
           9       0.95      0.45      0.61       480
          10       0.86      0.70      0.77       660
          11       1.00      0.08      0.15       420
          12       1.00      0.97      0.98       690
          13       1.00      0.99      1.00       720
          14       0.98      0.93      0.95       270
          15       0.30      0.99      0.46       210
          16       0.36      0.99      0.53       150
          17       1.00      0.71      0.83       360
          18       0.96      0.17      0.29       390
          19       0.24      0.98      0.38        60
          20       0.43      0.89      0.58        90
```

```python
          21       0.47      0.72      0.57        90
          22       0.39      0.78      0.53       120
          23       0.37      0.56      0.44       150
          24       0.27      0.86      0.42        90
          25       0.99      0.26      0.41       480
          26       0.38      0.58      0.46       180
          27       0.32      1.00      0.49        60
          28       0.38      0.50      0.43       150
          29       0.35      0.73      0.47        90
          30       0.26      0.34      0.30       150
          31       0.84      0.86      0.85       270
          32       0.73      0.93      0.82        60
          33       0.94      0.88      0.91       210
          34       0.49      0.98      0.65       120
          35       1.00      0.66      0.79       390
          36       0.78      1.00      0.88       120
          37       0.76      0.92      0.83        60
          38       1.00      0.66      0.79       690
          39       0.96      0.97      0.96        90
          40       0.52      0.90      0.66        90
          41       0.38      0.62      0.47        60
          42       0.54      0.88      0.67        90

    accuracy                           0.66     12630
   macro avg       0.66      0.73      0.63     12630
weighted avg       0.81      0.66      0.68     12630
```

- T·∫°i bi·ªÉn b√°o nh√£n 0 (Speed Limit 20) c√≥ ch·ªâ s·ªë precision r·∫•t th·∫•p (9%) ƒëi·ªÅu n√†y x·∫£y ra l√† do h·∫ßu h·∫øt c√°c bi·ªÉn b√°o speed limit c√≥ h√¨nh d√°ng kh√° t∆∞∆°ng ƒë·ªìng, ch·ªâ thay ƒë·ªïi m·ªói con s·ªë ·ªü trong bi·ªÉn b√°o. Vi·ªác s·ª≠ d·ª•ng HOG tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ·∫£nh v·ªõi t·ªâ l·ªá ·∫£nh l√† 128\*128px c≈©ng s·∫Ω l√†m cho nh·ªØng con s·ªë trong bi·ªÉn b√°o tr·ªü n√™n kh√≥ ph√¢n bi·ªát h∆°n v·ªõi m√¥ h√¨nh KNN, ch√≠nh v√¨ v·∫≠y m√† t·ªâ l·ªá precision c·ªßa bi·ªÉn nh√£n 0 r·∫•t th·∫•p v√† t·ªâ l·ªá recall l·∫°i cao h∆°n so v·ªõi c√°c bi·ªÉn speed limit kh√°c (t·ª´ 1 - 8). Ngo√†i ra s·ªë support c≈©ng th·∫•p h∆°n so v·ªõi c√°c bi·ªÉn c√≤n l·∫°i c≈©ng d·∫´n ƒë·∫øn vi·ªác ch·ªâ s·ªë recall cao.
- ƒêi·ªÅu n√†y c≈©ng x·∫£y ra t∆∞∆°ng t·ª± v·ªõi bi·ªÉn s·ªë 11 v√† bi·ªÉn s·ªë 27 khi h√¨nh d√°ng kh√° t∆∞∆°ng t·ª± nhau:

Nh·ªØng ·∫£nh c√≥ h√¨nh d√°ng t∆∞∆°ng t·ª± nhau s·∫Ω g√¢y ra s·ª± nh·∫ßm l·∫´n l·ªõn ƒë·ªëi v·ªõi m√¥ h√¨nh KNN

Nh√¨n chung vi·ªác s·ª≠ d·ª•ng m√¥ h√¨nh KNN ƒë·ªÉ ƒë√°nh gi√° v·ªõi c√°c t·∫≠p d·ªØ li·ªáu l·ªõn v√† c√≥ ƒë·ªô ph·ª©c t·∫°p cao v·ªÅ c·∫£ d·ªØ li·ªáu v√† kh√¥ng gian ƒë·∫∑c tr∆∞ng s·∫Ω ƒëem l·∫°i hi·ªáu qu·∫£ r·∫•t k√©m. V·ªõi kh√¥ng gian v·ªõi 8100 chi·ªÅu th√¨ c√°c m·∫´u s·∫Ω tr·ªü n√™n xa nhau trong kh√¥ng gian ƒë·∫∑c tr∆∞ng, l√†m cho vi·ªác t√¨m l√°ng gi·ªÅng g·∫ßn nh·∫•t tr·ªü n√™n kh√≥ khƒÉn v√† kh√¥ng ch√≠nh x√°c.

## 3.3. T·ªëi ∆∞u model

Sau qu√° tr√¨nh ƒë√°nh gi√° th√¨ t√¥i ƒë√£ quy·∫øt ƒë·ªãnh ch·ªçn 2 model ƒë·ªÉ ti·∫øn h√†nh stacking s·ª≠ d·ª•ng Logistic Regrestion ƒë·ªÉ ch·ªçn k·∫øt qu·∫£ t·ªët nh·∫•t. Tr∆∞·ªõc ƒë√≥ t√¥i s·∫Ω ti·∫øn h√†nh t·ªëi ∆∞u model SVM s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p Grid Search:

### 3.3.1. T·ªëi ∆∞u model SVM

```python
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt

# Danh s√°ch c√°c gi√° tr·ªã c·ªßa si√™u tham s·ªë c·∫ßn ƒëi·ªÅu ch·ªânh
param_grid = {'C': [0.01, 0.03, 0.05, 0.07, 0.1]}

# T·∫°o GridSearchCV v·ªõi m√¥ h√¨nh SVM v√† si√™u tham s·ªë ƒë√£ cho
grid_search = GridSearchCV(estimator=model_svm, param_grid=param_grid, cv=5)

# Hu·∫•n luy·ªán GridSearchCV tr√™n d·ªØ li·ªáu
grid_search.fit(x_train, y_train)

# L·∫•y k·∫øt qu·∫£ c·ªßa Grid Search
results = grid_search.cv_results_
```

T√¥i s·∫Ω s·ª≠ d·ª•ng Grid Search ƒë·ªÉ t√¨m ki·∫øm si√™u tham s·ªë t·ªëi ∆∞u cho m√¥ h√¨nh SVM. C·ª• th·ªÉ, ch√∫ng ta ƒë√£ x√°c ƒë·ªãnh m·ªôt danh s√°ch c√°c gi√° tr·ªã cho tham s·ªë "C", ƒë√¢y l√† tham s·ªë quan tr·ªçng trong SVM.

Sau ƒë√≥, t√¥i s·ª≠ d·ª•ng GridSearchCV ƒë·ªÉ th·ª≠ t·∫•t c·∫£ c√°c gi√° tr·ªã trong danh s√°ch ƒë√≥ v√† ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh SVM v·ªõi m·ªói gi√° tr·ªã c·ªßa "C" tr√™n t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán. B·∫±ng c√°ch n√†y, t√¥i c√≥ th·ªÉ t√¨m ra gi√° tr·ªã t·ªëi ∆∞u cho "C" m√† c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh.

Sau khi th·ª≠ v·ªõi c√°c gi√° tr·ªã C kh√°c nhau t·ª´ $10^{-3}$ cho ƒë·∫øn 10 th√¨ gi√° tr·ªã t·ªët nh·∫•t l√† 0.01 v√† t√¥i ti·∫øp t·ª•c thu h·∫πp ph·∫°m vi v√† nh·∫≠n th·∫•y gi√° tr·ªã C m·∫∑c ƒë·ªãnh v·∫´n l√† 0.01 s·∫Ω cho ra ƒë·ªô ch√≠nh x√°c cao nh·∫•t.

V√¨ th·∫ø t√¥i s·∫Ω gi·ªØ nguy√™n si√™u tham s·ªë n√†y ƒë·ªÉ ti·∫øn h√†nh stacking

### 3.3.2. Training cho **meta-model**

Quy tr√¨nh:

Do t√†i nguy√™n c·ªßa m√°y t√¥i kh√¥ng ƒë·ªß ƒë·ªÉ th·ª±c hi·ªán gridsearch t√¨m si√™u tham s·ªë t·ªëi ∆∞u nh·∫•t v·ªõi m√¥ h√¨nh Random Forest n√™n t√¥i s·∫Ω ti·∫øn h√†nh lu√¥n b∆∞·ªõc hu·∫•n luy·ªán cho meta model

```python
model_svm = SVC(probability=True)
model_rf = RandomForestClassifier()
model_svm.fit(x_train, y_train) # Gi·ªØ nguy√™n si√™u tham s·ªë m·∫∑c ƒë·ªãnh
model_rf.fit(x_train, y_train)
svm_test_prob = model_svm.predict_proba(x_test)
rf_test_prob = model_rf.predict_proba(x_test)
```

ƒê·∫ßu ti√™n t√¥i kh·ªüi t·∫°o 2 m√¥ h√¨nh c∆° s·ªü hi·ªáu qu·∫£ nh·∫•t trong 3 m√¥ h√¨nh t√¥i ƒë√£ ƒë√°nh gi√° tr∆∞·ªõc ƒë√≥. Sau ƒë√≥ t·∫°o m√¥ m·ªôt ma tr·∫≠n ƒë·∫∑c tr∆∞ng l√†m ƒë·∫ßu v√†o hu·∫•n luy·ªán cho meta-model:

```python
# K·∫øt h·ª£p x√°c su·∫•t d·ª± ƒëo√°n ƒë·ªÉ t·∫°o th√†nh ma tr·∫≠n ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o cho m√¥ h√¨nh t·ªïng h·ª£p
train_stacked_features = np.hstack((svm_train_prob, rf_train_prob))
test_stacked_features = np.hstack((svm_test_prob, rf_test_prob))
# Hu·∫•n luy·ªán m√¥ h√¨nh t·ªïng h·ª£p (Logistic Regression) tr√™n t·∫≠p hu·∫•n luy·ªán
stacked_model = LogisticRegression()
stacked_model.fit(train_stacked_features, y_train)
```

## 3.4. ƒê√°nh gi√° meta-model

### 3.4.1. Accuracy

```python
Accuracy of svm model: 0.942596991290578
Accuracy of random forest model: 0.9338875692794932
Accuracy of stacked model: 0.9451702296120348
```

C√≥ th·ªÉ th·∫•y b·∫±ng

# 4. H∆∞·ªõng ph√°t tri·ªÉn v√† c·∫£i ti·∫øn

## **4.1. C·∫£i ti·∫øn trong t∆∞∆°ng lai**

**V·ªÅ data:**

- B·ªï sung ƒëa d·∫°ng c√°c lo·∫°i bi·ªÉn b√°o kh√°c, ƒë·∫∑c bi·ªát l√† bi·ªÉn b√°o giao th√¥ng Vi·ªát Nam
- T√¨m hi·ªÉu th√™m c√°c kƒ© thu·∫≠t tƒÉng c∆∞·ªùng data. Vi·ªác √°p d·ª•ng kh√¥ng hi·ªáu qu·∫£ c√°c kƒ© thu·∫≠t tƒÉng c∆∞·ªùng d·ªØ li·ªáu trong d·ª± √°n n√†y c√†ng cho th·∫•y tuy s·ªë l∆∞·ª£ng d·ªØ li·ªáu quan tr·ªçng nh∆∞ng ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu c≈©ng l√† m·ªôt y·∫øu t·ªë ·∫£nh h∆∞·ªüng m·∫°nh m·∫Ω t·ªõi ƒë·ªô ch√≠nh x√°c model.
- Vi·ªác s·ª≠ d·ª•ng th∆∞ vi·ªán SMOTE ƒë·ªÉ tƒÉng c∆∞·ªùng d·ªØ li·ªáu ·∫£nh sau ƒë√≥ chia th√†nh 3 t·∫≠p c√≥ th·ªÉ l√†m cho d·ªØ li·ªáu b·ªã overfitting l√†m gi·∫£m hi·ªáu qu·∫£ ƒë√°nh gi√°. Ch√∫ng t√¥i s·∫Ω t√¨m hi·ªÉu th√™m nh·ªØng c√°ch kh√°c ƒë·ªÉ tƒÉng c∆∞·ªùng d·ªØ li·ªáu, tuy s·ªë l∆∞·ª£ng d·ªØ li·ªáu quan tr·ªçng nh∆∞ng ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu c≈©ng l√† m·ªôt y·∫øu t·ªë ·∫£nh h∆∞·ªüng m·∫°nh m·∫Ω t·ªõi ƒë·ªô ch√≠nh x√°c model.

**V·ªÅ thu·∫≠t to√°n:**

- √Åp d·ª•ng c√°c k·ªπ thu·∫≠t Ensemble kh√°c thay v√¨ ch·ªâ s·ª≠ d·ª•ng Stacking
- TƒÉng s·ªë l∆∞·ª£ng base model ƒë·ªÉ tƒÉng ƒë·ªô nh·∫≠n di·ªán c·ªßa meta-model
- T√¨m ki·∫øm c√°c si√™u tham s·ªë hi·ªáu qu·∫£ h∆°n khi c√≥ ƒë·ªß ƒëi·ªÅu ki·ªán

## 4.2. H∆∞·ªõng ph√°t tri·ªÉn

- Thu th·∫≠p th√™m c√°c ·∫£nh c√≥ ngo·∫°i c·∫£nh v√† th·ª±c hi·ªán label b·∫±ng tay s·ª≠ d·ª•ng **bounding box.**
- Nh·∫≠n di·ªán bi·ªÉn b√°o trong th·ªùi gian th·ª±c v√† tr·∫£ v·ªÅ ƒë·∫ßu ra d∆∞·ªõi d·∫°ng √¢m thanh cho ng∆∞·ªùi d√πng.
- Nh·∫≠n bi·∫øt ƒë∆∞·ª£c bi·ªÉn b√°o v√† ph√¢n lo·∫°i ƒë∆∞·ª£c ch√≠nh x√°c lo·∫°i bi·ªÉn b√°o.

# 5. Video demo

Youtube link

# 6. Ngu·ªìn tham kh·∫£o

1. Data set: [GTSRB - German Traffic Sign Recognition Benchmark (kaggle.com)](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign)
2. HOG:¬†https://viblo.asia/p/tim-hieu-ve-phuong-phap-mo-ta-dac-trung-hog-histogram-of-oriented-gradients-V3m5WAwxZO7
3. M·∫•t c√¢n b·∫±ng d·ªØ li·ªáu: [Khoa h·ªçc d·ªØ li·ªáu (phamdinhkhanh.github.io)](https://phamdinhkhanh.github.io/2020/02/17/ImbalancedData.html)
4. GridSearchCV: [T·ª± h·ªçc ML | ƒêi·ªÅu ch·ªânh si√™u tham s·ªë SVM b·∫±ng GridSearchCV | ML ¬ª Cafedev.vn](https://cafedev.vn/tu-hoc-ml-dieu-chinh-sieu-tham-so-svm-bang-gridsearchcv-ml/)
5. SVM:¬†https://machinelearningcoban.com/2017/04/09/smv/
