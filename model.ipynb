{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc tệp dữ liệu đã tiền xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import logging\n",
    "from PIL import Image\n",
    "from skimage import feature\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import sys\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_csv(input):\n",
    "    csv.field_size_limit(2**31 - 1)\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(input, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader) # Skip title\n",
    "        for row in reader:\n",
    "            hog = np.array(literal_eval(row[0])) # Chuyển str -> list\n",
    "            label = int(row[1])\n",
    "            data.append(hog)\n",
    "            labels.append(label)\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thực hiện training bằng SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_pkl(model, output_file):\n",
    "    joblib.dump(model, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_pkl(input_file):\n",
    "    return joblib.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tải dữ liệu đã được tiền xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = read_data_from_csv('./data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='hinge')  # Sử dụng SVM với SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã huấn luyện batch từ 0 đến 3000\n",
      "Đã huấn luyện batch từ 3000 đến 6000\n",
      "Đã huấn luyện batch từ 6000 đến 9000\n",
      "Đã huấn luyện batch từ 9000 đến 12000\n",
      "Đã huấn luyện batch từ 12000 đến 15000\n",
      "Đã huấn luyện batch từ 15000 đến 18000\n",
      "Đã huấn luyện batch từ 18000 đến 21000\n",
      "Đã huấn luyện batch từ 21000 đến 24000\n",
      "Đã huấn luyện batch từ 24000 đến 27000\n",
      "Đã huấn luyện batch từ 27000 đến 30000\n",
      "Đã huấn luyện batch từ 30000 đến 33000\n",
      "Đã huấn luyện batch từ 33000 đến 36000\n",
      "Đã huấn luyện batch từ 36000 đến 39000\n",
      "Đã huấn luyện batch từ 39000 đến 42000\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình theo từng batch\n",
    "batch_size = 3000\n",
    "for start in range(0, len(X_train), batch_size):\n",
    "    end = start + batch_size\n",
    "    X_batch = X_train[start:end]\n",
    "    y_batch = y_train[start:end]\n",
    "    model.partial_fit(X_batch, y_batch, classes=np.unique(y_train))\n",
    "    print(f\"Đã huấn luyện batch từ {start} đến {end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình đã được lưu thành công vào file 'svm_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "save_model_pkl(model, 'svm_model.pkl')\n",
    "print(\"Mô hình đã được lưu thành công vào file 'svm_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training bằng RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_random_forest(X_train, y_train, batch_size=3000):\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, warm_start=True)\n",
    "    for start in range(0, len(X_train), batch_size):\n",
    "        end = start + batch_size\n",
    "        X_batch = X_train[start:end]\n",
    "        y_batch = y_train[start:end]\n",
    "        if start == 0:\n",
    "            model.fit(X_batch, y_batch)\n",
    "        else:\n",
    "            model.n_estimators += 10\n",
    "            model.fit(X_batch, y_batch)\n",
    "        print(f\"Đã huấn luyện batch từ {start} đến {end}\")\n",
    "    save_model_pkl(model, 'rf_model.pkl')\n",
    "    print(\"Mô hình Random Forest đã được lưu thành công vào file 'rf_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã huấn luyện batch từ 0 đến 3000\n",
      "Đã huấn luyện batch từ 3000 đến 6000\n",
      "Đã huấn luyện batch từ 6000 đến 9000\n",
      "Đã huấn luyện batch từ 9000 đến 12000\n",
      "Đã huấn luyện batch từ 12000 đến 15000\n",
      "Đã huấn luyện batch từ 15000 đến 18000\n",
      "Đã huấn luyện batch từ 18000 đến 21000\n",
      "Đã huấn luyện batch từ 21000 đến 24000\n",
      "Đã huấn luyện batch từ 24000 đến 27000\n",
      "Đã huấn luyện batch từ 27000 đến 30000\n",
      "Đã huấn luyện batch từ 30000 đến 33000\n",
      "Đã huấn luyện batch từ 33000 đến 36000\n",
      "Đã huấn luyện batch từ 36000 đến 39000\n",
      "Đã huấn luyện batch từ 39000 đến 42000\n",
      "Mô hình Random Forest đã được lưu thành công vào file 'rf_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "train_random_forest(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training bằng Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã huấn luyện batch từ 0 đến 3000\n",
      "Đã huấn luyện batch từ 3000 đến 6000\n",
      "Đã huấn luyện batch từ 6000 đến 9000\n",
      "Đã huấn luyện batch từ 9000 đến 12000\n",
      "Đã huấn luyện batch từ 12000 đến 15000\n",
      "Đã huấn luyện batch từ 15000 đến 18000\n",
      "Đã huấn luyện batch từ 18000 đến 21000\n",
      "Đã huấn luyện batch từ 21000 đến 24000\n",
      "Đã huấn luyện batch từ 24000 đến 27000\n",
      "Đã huấn luyện batch từ 27000 đến 30000\n",
      "Đã huấn luyện batch từ 30000 đến 33000\n",
      "Đã huấn luyện batch từ 33000 đến 36000\n",
      "Đã huấn luyện batch từ 36000 đến 39000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     save_model_pkl(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbm_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMô hình Gradient Boosting đã được lưu thành công vào file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbm_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtrain_gradient_boosting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[47], line 9\u001b[0m, in \u001b[0;36mtrain_gradient_boosting\u001b[1;34m(X_train, y_train, batch_size)\u001b[0m\n\u001b[0;32m      7\u001b[0m     X_batch \u001b[38;5;241m=\u001b[39m X_train[start:end]\n\u001b[0;32m      8\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_train[start:end]\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mĐã huấn luyện batch từ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m đến \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m save_model_pkl(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbm_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Setting_code\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Setting_code\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:665\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    663\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight_is_none:\n\u001b[1;32m--> 665\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_y(y\u001b[38;5;241m=\u001b[39my, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32md:\\Setting_code\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:1520\u001b[0m, in \u001b[0;36mGradientBoostingClassifier._encode_y\u001b[1;34m(self, y, sample_weight)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     n_trim_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcount_nonzero(np\u001b[38;5;241m.\u001b[39mbincount(encoded_y_int, sample_weight))\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_trim_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1521\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m class after sample_weight \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrimmed classes with zero weights, while a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1523\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimum of 2 classes are required.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m n_trim_classes\n\u001b[0;32m   1524\u001b[0m     )\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_y\n",
      "\u001b[1;31mValueError\u001b[0m: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def train_gradient_boosting(X_train, y_train, batch_size=3000):\n",
    "    model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    for start in range(0, len(X_train), batch_size):\n",
    "        end = start + batch_size\n",
    "        X_batch = X_train[start:end]\n",
    "        y_batch = y_train[start:end]\n",
    "        model.fit(X_batch, y_batch)\n",
    "        print(f\"Đã huấn luyện batch từ {start} đến {end}\")\n",
    "    save_model_pkl(model, 'gbm_model.pkl')\n",
    "    print(\"Mô hình Gradient Boosting đã được lưu thành công vào file 'gbm_model.pkl'\")\n",
    "\n",
    "train_gradient_boosting(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
